{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tutorial 2: Feature detection\n",
    "\n",
    "This tutorial was adapted from https://github.com/scikit-image/skimage-tutorials/blob/master/lectures/2_feature_detection.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Feature detection is often the end result of image processing. We'll detect some basic features (edges, points, and circles) in this section, but there are a wealth of feature detectors that are available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Edge detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Before we start, let's set the default colormap to grayscale and turn off pixel interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "plt.rcParams['image.interpolation'] = 'none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We've already discussed edge filtering, using the Sobel filter, in the last section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import data\n",
    "from skimage import filters\n",
    "\n",
    "image = data.camera()\n",
    "pixelated = image[::10, ::10]\n",
    "gradient = filters.sobel(pixelated)\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "ax[0].imshow(pixelated)\n",
    "ax[1].imshow(gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "With the Sobel filter, however, we get back a grayscale image, which essentially tells us the likelihood that a pixel is on the edge of an object.\n",
    "\n",
    "We can apply a bit more logic to *detect* an edge; i.e. we can use that filtered image to make a *decision* whether or not a pixel is on an edge. The simplest way to do that is with thresholding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "ax[0].imshow(gradient)\n",
    "ax[1].imshow(gradient > 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "That approach doesn't do a great job. It's noisy and produces thick edges. Furthermore, it doesn't use our *knowledge* of how edges work: They should be thin and tend to be connected along the direction of the edge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Canny edge detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The Canny edge detector combines the Sobel filter with a few other steps to give a binary edge image. The steps are as follows:\n",
    "* Gaussian filter\n",
    "* Sobel filter\n",
    "* Non-maximal suppression\n",
    "* Hysteresis thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Let's go through these steps one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 1: Gaussian filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "As discussed earlier, gradients tend to enhance noise. To combat this effect, we first smooth the image using a gradient filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import img_as_float\n",
    "\n",
    "sigma = 1  # Standard-deviation of Gaussian; larger smooths more.\n",
    "pixelated_float = img_as_float(pixelated)\n",
    "pixelated_float = pixelated\n",
    "smooth = filters.gaussian(pixelated_float, sigma)\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "ax[0].imshow(pixelated_float)\n",
    "ax[1].imshow(smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 2: Sobel filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Next, we apply our edge filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gradient_magnitude = filters.sobel(smooth)\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "ax[0].imshow(smooth)\n",
    "ax[1].imshow(gradient_magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 3: Non-maximal suppression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Goal: Suppress gradients that aren't on an edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Ideally, an edge is thin: In some sense, an edge is infinitely thin, but images are discrete so we want edges to be a single pixel wide. To accomplish this, we thin the image using \"non-maximal suppression\". This takes the edge-filtered image and thins the response *across* the edge direction; i.e. in the direction of the maximum gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "zoomed_grad = gradient_magnitude[15:25, 5:15]\n",
    "maximal_mask = np.zeros_like(zoomed_grad)\n",
    "# This mask is made up for demo purposes\n",
    "maximal_mask[range(10), (7, 6, 5, 4, 3, 2, 2, 2, 3, 3)] = 1\n",
    "grad_along_edge = maximal_mask * zoomed_grad\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "ax[0].imshow(zoomed_grad)\n",
    "ax[1].imshow(grad_along_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Obviously, this is a faked version of non-maximal suppression: Pixels are *manually* masked here. The actual algorithm detects the direction of edges, and keeps a pixel only if it has a locally maximal gradient-magnitude in the direction *normal to the edge direction*. It doesn't mask pixels *along* the edge direction since an adjacent edge pixel will be of comparable magnitude.\n",
    "\n",
    "The result of the filter is that an edge is only possible if there are no better edges near it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 4: Hysteresis thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Goal: Prefer pixels that are connected to edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The final step is the actual decision-making process. Here, we have two parameters: The low threshold and the high threshold. The high threshold sets the gradient value that you *know* is definitely an edge. The low threshold sets the gradient value that could be an edge, but only if it's connected to a pixel that we know is an edge.\n",
    "\n",
    "These two thresholds are displayed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from skimage import color\n",
    "\n",
    "low_threshold = 0.2\n",
    "high_threshold = 0.3\n",
    "label_image = np.zeros_like(pixelated)\n",
    "# This uses `gradient_magnitude` which has NOT gone through non-maximal-suppression.\n",
    "label_image[gradient_magnitude > low_threshold] = 1\n",
    "label_image[gradient_magnitude > high_threshold] = 2\n",
    "demo_image = color.label2rgb(label_image, gradient_magnitude,\n",
    "                             bg_label=0, colors=('yellow', 'red'))\n",
    "plt.imshow(demo_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The **red points** here are above `high_threshold` and are seed points for edges. The **yellow points** are edges if connected (possibly by other yellow points) to seed points; i.e. isolated groups of yellow points will not be detected as edges.\n",
    "\n",
    "Note that the demo above is on the edge image *before* non-maximal suppression, but in reality, this would be done on the image *after* non-maximal suppression. There isn't currently an easy way to get at the intermediate result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### All-in-one: The Canny edge detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Now we're ready to look at the actual result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "canny_edge = feature.canny(pixelated)\n",
    "fig, ax = plt.subplots(ncols=2, figsize=(20, 10))\n",
    "ax[0].imshow(pixelated)\n",
    "ax[1].imshow(canny_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hough transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Hough transforms are a general class of operations that make up a step in feature detection. Just like we saw with edge detection, Hough transforms produce a result that we can use to detect a feature. (The distinction between the \"filter\" that we used for edge detection and the \"transform\" that we use here is a bit arbitrary.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Circle detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "To explore the Hough transform, let's take the *circular* Hough transform as our example. Let's grab an image with some circles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = data.coins()[0:95, 180:370]\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can use the Canny edge filter to get a pretty good representation of these circles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "edges = feature.canny(image, sigma=3, low_threshold=10, high_threshold=60)\n",
    "plt.imshow(edges);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "While it looks like we've extracted circles, this doesn't give us much if what we want to do is *measure* these circles. For example, what are the size and position of the circles in the above image? The edge image doesn't really tell us much about that.\n",
    "\n",
    "We'll use the Hough transform to extract circle positions and radii:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.transform import hough_circle\n",
    " \n",
    "hough_radii = np.arange(15, 30, 2)\n",
    "hough_response = hough_circle(edges, hough_radii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here, the circular Hough transform actually uses the edge image from before. We also have to define the radii that we want to search for in our image.\n",
    "\n",
    "So... what's the actual result that we get back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(edges.shape)\n",
    "print(hough_response.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We can see that the last two dimensions of the response are exactly the same as the original image, so the response is image-like. Then what does the first dimension correspond to?\n",
    "\n",
    "As always, you can get a better feel for the result by plotting it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Use max value to intelligently rescale the data for plotting.\n",
    "h_max = hough_response.max()\n",
    "fig, axes = plt.subplots(ncols=4, nrows=2, figsize=(20, 6))\n",
    "for h, r, ax in zip(hough_response, hough_radii, axes.ravel()):\n",
    "    ax.imshow(h, vmax=0.5*h_max)\n",
    "    ax.axis('off')\n",
    "    ax.set_title('radius %.0f' % r)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Use the response from the Hough transform to **detect the position of each coin**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "\n",
    "# A list of (row, column) tuples indicating \n",
    "# the coordinates of local peaks:\n",
    "centers = []\n",
    "# A list of likelihood values for each of the\n",
    "# local peaks above:\n",
    "likelihood = []\n",
    "\n",
    "# Hint\n",
    "# ----\n",
    "# To add a single element to a list, use `append`:\n",
    "# In [0]: mylist = [2]\n",
    "# ...     mylist.append(3)\n",
    "# Out[0]: [2, 3]\n",
    "#\n",
    "# To add multiple elements to a list, use `extend`:\n",
    "# In [1]: mylist = [2]\n",
    "# ...     mylist.extend([3, 4])\n",
    "# Out[1]: [2, 3, 4]\n",
    "\n",
    "for h in hough_response:\n",
    "    # Your code here...\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Exercise:\n",
    "\n",
    "Now repeat the above procedure for a more realistic image; e.g. detecting cell nuclei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "img = io.imread('../img/tissue.jpg', as_grey=True)\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = feature.canny(img)\n",
    "plt.imshow(edges);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to tweak Canny's optional arguments... have a look at `low_threshold` and `high_threshold`, too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = feature.canny(img, sigma=3)\n",
    "plt.imshow(edges);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The same concept described in this section can be applied to line detection, ellipse detection, and various other features of interest.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Further reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Interest point detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "We've only skimmed the surface of what might be classified as \"feature detection\". One major area that we haven't covered is called [interest point detection](http://en.wikipedia.org/wiki/Interest_point_detection). Here, we don't even need to know what we're looking for, we just identify small patches (centered on a pixel) that are \"distinct\". (The definition of \"distinct\" varies by algorithm; e.g., the Harris corner detector defines interest points as corners.) These distinct points can then be used to, e.g., compare with distinct points in other images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* [Probabilistic Hough transform](http://scikit-image.org/docs/dev/auto_examples/plot_line_hough_transform.html)\n",
    "* [Circular and elliptical Hough transforms](http://scikit-image.org/docs/dev/auto_examples/plot_circular_elliptical_hough_transform.html)\n",
    "* [Template matching](http://scikit-image.org/docs/dev/auto_examples/plot_template.html)\n",
    "* [Histogram of Oriented Gradients](http://scikit-image.org/docs/dev/auto_examples/plot_hog.html)\n",
    "* [BRIEF](http://scikit-image.org/docs/dev/auto_examples/plot_brief.html), [CENSURE](http://scikit-image.org/docs/dev/auto_examples/plot_censure.html), and [ORB](http://scikit-image.org/docs/dev/auto_examples/plot_orb.html) feature detectors/descriptors\n",
    "* [Robust matching using RANSAC](http://scikit-image.org/docs/dev/auto_examples/plot_matching.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
